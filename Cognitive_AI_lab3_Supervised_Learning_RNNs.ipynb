{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH8uH8rx6MTg"
      },
      "source": [
        "#Training RNNs on cognitive tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YTRThwxByWbI"
      },
      "outputs": [],
      "source": [
        "# # Uninstall the current Gym version\n",
        "# !pip uninstall -y gym\n",
        "\n",
        "# # Install Gym version 0.23.1\n",
        "# !pip install gym==0.23.1\n",
        "\n",
        "# # Restart the runtime after installation (necessary in some environments like Colab)\n",
        "# import os\n",
        "# os._exit(00)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtd39htCstwB"
      },
      "source": [
        "#Introduction\n",
        "\n",
        "In lab 1 we explored the architecture and dynamics of Recurrent Neural Networks (RNNs). Now, we transition from understanding the mechanics of RNNs to deploying them effectively on cognitive tasks. We’ll explore how these networks, inspired by the recurrent connections in our brain, can be trained to perform tasks that mimic cognitive functions. Engaging in such exercises not only offers insights into artificial intelligence but also sheds light on the computational capabilities of our own neural circuits.\n",
        "\n",
        "We will train our network to perform a perceptual decision-making task. In the laboratory, the test subject (human or animal) is shown moving dots on a screen, and must respond to indicate whether most dots are moving to the left or right. By recording from different brain areas, neuroscientists have been able to isolate the brain areas where the evidence accumulates in order to make this type of perceptual decision [(review paper)](https://www.cell.com/neuron/fulltext/S0896-6273(13)00999-9?script=true&code=cell-site).\n",
        "Let's take a closer look at how this cognitive task is performed in real life to deepen our understanding. Here is a [link](https://www.youtube.com/watch?v=oDxcyTn-0os&ab_channel=PamelaReinagelatUCSD) to a video featuring a rat executing this perceptual decision-making task.\n",
        "\n",
        "We will build and train our network using pytorch, and then do the same using only numpy, to understand how the pytorch magic works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzU7LCTOKwof"
      },
      "source": [
        "Now, let's proceed with our main topic for today - training RNNs on cognitive tasks!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNsCB508r3UZ"
      },
      "source": [
        "### Installing and importing relevant packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drHbsMbKr3Ua",
        "outputId": "6cd89c43-3208-4584-8293-6166cd413b8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pigwi\\Coding\\Cognitive-AI\\neurogym\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'neurogym' already exists and is not an empty directory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obtaining file:///C:/Users/pigwi/Coding/Cognitive-AI/neurogym\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Checking if build backend supports build_editable: started\n",
            "  Checking if build backend supports build_editable: finished with status 'done'\n",
            "  Getting requirements to build editable: started\n",
            "  Getting requirements to build editable: finished with status 'done'\n",
            "  Preparing editable metadata (pyproject.toml): started\n",
            "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: pydantic-settings in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from neurogym==2.2.0) (2.11.0)\n",
            "Requirement already satisfied: loguru in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from neurogym==2.2.0) (0.7.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from neurogym==2.2.0) (4.67.1)\n",
            "Requirement already satisfied: tomlkit in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from neurogym==2.2.0) (0.13.3)\n",
            "Requirement already satisfied: numpy==2.1.* in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from neurogym==2.2.0) (2.1.3)\n",
            "Requirement already satisfied: gymnasium==0.29.* in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from neurogym==2.2.0) (0.29.1)\n",
            "Requirement already satisfied: matplotlib==3.9.* in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from neurogym==2.2.0) (3.9.4)\n",
            "Requirement already satisfied: scipy==1.14.* in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from neurogym==2.2.0) (1.14.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from gymnasium==0.29.*->neurogym==2.2.0) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from gymnasium==0.29.*->neurogym==2.2.0) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from gymnasium==0.29.*->neurogym==2.2.0) (0.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from matplotlib==3.9.*->neurogym==2.2.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from matplotlib==3.9.*->neurogym==2.2.0) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from matplotlib==3.9.*->neurogym==2.2.0) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from matplotlib==3.9.*->neurogym==2.2.0) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from matplotlib==3.9.*->neurogym==2.2.0) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from matplotlib==3.9.*->neurogym==2.2.0) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from matplotlib==3.9.*->neurogym==2.2.0) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from matplotlib==3.9.*->neurogym==2.2.0) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from python-dateutil>=2.7->matplotlib==3.9.*->neurogym==2.2.0) (1.17.0)\n",
            "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from loguru->neurogym==2.2.0) (0.4.6)\n",
            "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from loguru->neurogym==2.2.0) (1.2.0)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from pydantic-settings->neurogym==2.2.0) (2.12.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from pydantic-settings->neurogym==2.2.0) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from pydantic-settings->neurogym==2.2.0) (0.4.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from pydantic>=2.7.0->pydantic-settings->neurogym==2.2.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\pigwi\\miniconda3\\envs\\cog-ai\\lib\\site-packages (from pydantic>=2.7.0->pydantic-settings->neurogym==2.2.0) (2.41.4)\n",
            "Building wheels for collected packages: neurogym\n",
            "  Building editable for neurogym (pyproject.toml): started\n",
            "  Building editable for neurogym (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for neurogym: filename=neurogym-2.2.0-0.editable-py3-none-any.whl size=13157 sha256=b55276ead48ec2523f898c0267b3e3d5a7af97c38833a42386339121b10f14a5\n",
            "  Stored in directory: C:\\Users\\pigwi\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-1awu9tmr\\wheels\\af\\a5\\fe\\25f5a35a4e2483b86390ea8faffdadca57077208f6111b6ce1\n",
            "Successfully built neurogym\n",
            "Installing collected packages: neurogym\n",
            "  Attempting uninstall: neurogym\n",
            "    Found existing installation: neurogym 2.2.0\n",
            "    Uninstalling neurogym-2.2.0:\n",
            "      Successfully uninstalled neurogym-2.2.0\n",
            "Successfully installed neurogym-2.2.0\n"
          ]
        }
      ],
      "source": [
        "# Install neurogym to use cognitive tasks\n",
        "! git clone https://github.com/neurogym/neurogym.git\n",
        "%cd neurogym/\n",
        "! pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BYIY5KJtr3Ua"
      },
      "outputs": [],
      "source": [
        "# Import common packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjpUvzGNr3Ua"
      },
      "source": [
        "## Defining a recurrent neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "incorporated-editor"
      },
      "source": [
        "In general, recurrent neural networks transform **sequence to sequence**. In the context of cognitive neuroscience, the sequence is usually a time series of task input or output. Recall the sequence we produced in Tutorial 1 by executing a forward pass through an RNN?\n",
        "\n",
        "Let's understand the input and output dimensions of a typical recurrent network in machine learning, LSTM networks.\n",
        "\n",
        "(Usage example adopted from pytorch documentation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VGmZ7mtr3Ub",
        "outputId": "9e9b1f4e-837c-43f8-a9d4-d4bd2291b6df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output shape is (SeqLen, BatchSize, HiddenSize): torch.Size([5, 3, 20])\n"
          ]
        }
      ],
      "source": [
        "# Make a LSTM, with input_size =10,\n",
        "# hidden_size is the number of hidden neurons = 20\n",
        "# number of layers = 2\n",
        "# checkout the pytorch LSTM documentation\n",
        "rnn = nn.LSTM(input_size=10,\n",
        "              hidden_size=20,\n",
        "              num_layers=2\n",
        "              )\n",
        "\n",
        "# Generate some mock inputs\n",
        "input = torch.randn(5, 3, 10)  # The arguments represent (Sequence Length, Batch Size, Input Size). Typically, in neuroscience,\n",
        "# sequence length would correspond to time points in the time series, Batch size corresponds to the number of trials and\n",
        "# input size corresponds to the dimension of the input (ie., the number of neurons or channels you're collecting data from)\n",
        "output, (hn, cn) = rnn(input)\n",
        "\n",
        "print('Output shape is (SeqLen, BatchSize, HiddenSize):', output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg9fY5C4_snE"
      },
      "source": [
        "##**Defining a Leaky Recurrent Neural Network **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "proper-armor"
      },
      "source": [
        "Neuroscientists often prefer **Leaky Recurrent Neural Networks (Leaky RNNs)** due to their ability to accurately model the continuous and dynamic nature of biological neural processes. Leaky RNNs can mimic the temporal dynamics and adaptive learning capabilities of biological neural networks, providing a closer approximation to real neurological processes. Furthermore, their robustness in handling noisy environments, capability to generate complex behaviors, and applicability in studying real-time interactions and sensorimotor coordination make them a valuable tool in neuroscience research and experimentation.\n",
        "\n",
        "Let us define a continuous-time leaky recurrent neural network,\n",
        "\\begin{align}\n",
        "    \\tau \\frac{d\\mathbf{a}}{dt} = -\\mathbf{a}(t) + f(W_{a\\rightarrow\n",
        "a} \\mathbf{a}(t) + W_{x\\rightarrow a} \\mathbf{x}(t) + \\mathbf{b}_1).\n",
        "\\end{align}\n",
        "\n",
        "Where,\n",
        "\n",
        "$a(t)$ is the vector of neural firing rates (or activations) at time $t$.\n",
        "\n",
        "$τ$ is the time constant which determines how fast the state approaches its steady-state value.\n",
        "\n",
        "$f$ is a non-linear activation function applied element-wise.\n",
        "\n",
        "$W_{a\\rightarrow a}$ is the recurrent weight matrix.\n",
        "\n",
        "$x(t)$ is the input vector at time $t$.\n",
        "\n",
        "$W_{x\\rightarrow a}$ is the input weight matrix.\n",
        "\n",
        "$b_1​$ is the bias vector.\n",
        "\n",
        "\n",
        "Let us discretize this network in time using the Euler method with a time step of $\\Delta t$,\n",
        "\\begin{align}\n",
        "    \\mathbf{a}(t+\\Delta t) = \\mathbf{a}(t) + \\Delta \\mathbf{a} &= \\mathbf{a}(t) + \\frac{\\Delta t}{\\tau}[-\\mathbf{a}(t) + f(W_{a\\rightarrow a} \\mathbf{a}(t) + W_{x\\rightarrow a}  \\mathbf{x}(t) + \\mathbf{b}_r)] \\\\\n",
        "    &= (1 - \\frac{\\Delta t}{\\tau})\\mathbf{a}(t) + \\frac{\\Delta t}{\\tau}f(W_{a\\rightarrow a} \\mathbf{a}(t) + W_{x\\rightarrow a}  \\mathbf{x}(t) + \\mathbf{b}_r)\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "friRVLXaMegj"
      },
      "source": [
        "Let us now define the network following the dynamics described by the above equation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "coupled-sessions"
      },
      "outputs": [],
      "source": [
        "class LeakyRNN(nn.Module):\n",
        "    \"\"\"Leaky RNN.\n",
        "\n",
        "    Parameters:\n",
        "        input_size: Number of input neurons\n",
        "        hidden_size: Number of hidden neurons\n",
        "        dt: discretization time step in ms.\n",
        "            If None, dt equals time constant tau\n",
        "\n",
        "    Inputs:\n",
        "        input: tensor of shape (seq_len, batch, input_size)\n",
        "        hidden: tensor of shape (batch, hidden_size), initial hidden activity\n",
        "            if None, hidden is initialized through self.init_hidden()\n",
        "\n",
        "    Outputs:\n",
        "        output: tensor of shape (seq_len, batch, hidden_size)\n",
        "        hidden: tensor of shape (batch, hidden_size), final hidden activity\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, dt=None, **kwargs):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.tau = 100\n",
        "        if dt is None:\n",
        "            alpha = 1\n",
        "        else:\n",
        "            alpha = dt / self.tau\n",
        "        self.alpha = alpha\n",
        "\n",
        "        self.input2h = nn.Linear(input_size, hidden_size)\n",
        "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def init_hidden(self, input_shape):\n",
        "        batch_size = input_shape[1]\n",
        "        return torch.zeros(batch_size, self.hidden_size)\n",
        "\n",
        "    def recurrence(self, input, hidden):\n",
        "        \"\"\"Run network for one time step.\n",
        "\n",
        "        Inputs:\n",
        "            input: tensor of shape (batch, input_size)\n",
        "            hidden: tensor of shape (batch, hidden_size)\n",
        "\n",
        "        Outputs:\n",
        "            h_new: tensor of shape (batch, hidden_size),\n",
        "                network activity at the next time step\n",
        "        \"\"\"\n",
        "        h_new = torch.relu(self.input2h(input) + self.h2h(hidden))\n",
        "\n",
        "        #implement how much the previous hidden layer activity should be maintained in the new activity\n",
        "        h_new = hidden * (1-self.alpha) + h_new * self.alpha\n",
        "        return h_new\n",
        "\n",
        "    def forward(self, input, hidden=None):\n",
        "        \"\"\"Propogate input through the network.\"\"\"\n",
        "\n",
        "        # If hidden activity is not provided, initialize it\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(input.shape).to(input.device)\n",
        "\n",
        "        # Loop through time\n",
        "        output = []\n",
        "        steps = range(input.size(0))\n",
        "        for i in steps:\n",
        "            hidden = self.recurrence(input[i], hidden)\n",
        "            output.append(hidden)\n",
        "\n",
        "        # Stack together output from all time steps\n",
        "        output = torch.stack(output, dim=0)  # (seq_len, batch, hidden_size)\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "class RNNNet(nn.Module):\n",
        "    \"\"\"Recurrent network model.\n",
        "\n",
        "    Parameters:\n",
        "        input_size: int, input size\n",
        "        hidden_size: int, hidden size\n",
        "        output_size: int, output size\n",
        "\n",
        "    Inputs:\n",
        "        x: tensor of shape (Seq Len, Batch, Input size)\n",
        "\n",
        "    Outputs:\n",
        "        out: tensor of shape (Seq Len, Batch, Output size)\n",
        "        rnn_output: tensor of shape (Seq Len, Batch, Hidden size)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        # Leaky RNN\n",
        "        self.rnn = LeakyRNN(input_size, hidden_size, **kwargs)\n",
        "\n",
        "        # Add a Linear output layer\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn_output, _ = self.rnn(x)\n",
        "        out = self.fc(rnn_output)\n",
        "        return out, rnn_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zscQyqJKAPsn"
      },
      "source": [
        "Let's determine the dimensions of its inputs and outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJiMYOS0A4QP",
        "outputId": "af198006-161e-4e31-f802-e8b259900a7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input of shape = torch.Size([20, 16, 5])\n",
            "Output of shape = torch.Size([20, 16, 10])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 16\n",
        "seq_len = 20  # sequence length\n",
        "input_size = 5  # input dimension\n",
        "\n",
        "# Make some random inputs\n",
        "input_rnn = torch.rand(seq_len, batch_size, input_size)\n",
        "\n",
        "# Make network of 100 hidden units and 10 output units\n",
        "rnn = RNNNet(5, 100, 10)\n",
        "\n",
        "# Run the sequence through the network\n",
        "out, rnn_output = rnn(input_rnn)\n",
        "\n",
        "print('Input of shape =', input_rnn.shape)\n",
        "print('Output of shape =', out.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "artificial-michael"
      },
      "source": [
        "## Defining a simple cognitive task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq0JWZh1JCFW"
      },
      "source": [
        "Here we use the neurogym package to make a simple \"perceptual decision making\" task. Let us install the package first.NeuroGym is a curated collection of neuroscience tasks with a common interface. You may explore further [here](https://github.com/neurogym/neurogym)\n",
        "\n",
        "The code provided below defines a custom environment, PerceptualDecisionMaking, using neurogym. This environment simulates a two-alternative forced choice task where an agent needs to decide which of two stimuli is higher on average, despite the stimuli being noisy. The agent is encouraged to integrate the stimulus over time due to this noise.\n",
        "\n",
        "Given that the focus of today's tutorial is on training an RNN, feel free to navigate through this section, which involves defining a cognitive task, at your own pace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3KQN9OCB_c8",
        "outputId": "d96d8de7-b02a-43ab-ea55-6469bef90e8a"
      },
      "outputs": [],
      "source": [
        "# @title importing neurogym\n",
        "import neurogym as ngym\n",
        "\n",
        "# Canned environment from neurogym\n",
        "# Copy the name of the Perceptual Decision Making environment from here: https://neurogym.github.io/envs/index.html\n",
        "task_name = 'PerceptualDecisionMaking-v0'\n",
        "# Importantly, we set discretization time step for the task as well\n",
        "kwargs = {'dt': 20, 'timing': {'stimulus': 1000}}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yro2ByHB_c9"
      },
      "source": [
        "For **supervised learning**, we need a dataset that returns (input, target output pairs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa-AtjsVB_c9",
        "outputId": "67ff0dcd-05df-4bbd-d5a9-60a199bb309e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input has shape (SeqLen, Batch, Dim) = torch.Size([100, 16, 3])\n",
            "Target has shape (SeqLen, Batch) = (100, 16)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pigwi\\miniconda3\\envs\\Cog-AI\\Lib\\site-packages\\gymnasium\\envs\\registration.py:481: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['paper_link', 'paper_name', 'tags']\u001b[0m\n",
            "  logger.warn(\n",
            "c:\\Users\\pigwi\\miniconda3\\envs\\Cog-AI\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.seed to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.seed` for environment variables or `env.get_wrapper_attr('seed')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "c:\\Users\\pigwi\\miniconda3\\envs\\Cog-AI\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.new_trial to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.new_trial` for environment variables or `env.get_wrapper_attr('new_trial')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "c:\\Users\\pigwi\\miniconda3\\envs\\Cog-AI\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.ob to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.ob` for environment variables or `env.get_wrapper_attr('ob')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "c:\\Users\\pigwi\\miniconda3\\envs\\Cog-AI\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.gt to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.gt` for environment variables or `env.get_wrapper_attr('gt')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ],
      "source": [
        "# Make supervised dataset\n",
        "seq_len = 100\n",
        "batch_size = 16\n",
        "#Create the dataset (Hover over ngym.Dataset to see input arguments)\n",
        "dataset = ngym.Dataset(task_name, env_kwargs=kwargs, batch_size=batch_size, seq_len=seq_len)\n",
        "env = dataset.env\n",
        "\n",
        "# Generate one batch of data when called\n",
        "inputs, target = dataset()\n",
        "inputs = torch.from_numpy(inputs).type(torch.float)\n",
        "\n",
        "input_size = env.observation_space.shape[0]\n",
        "output_size = env.action_space.n\n",
        "\n",
        "print('Input has shape (SeqLen, Batch, Dim) =', inputs.shape)\n",
        "print('Target has shape (SeqLen, Batch) =', target.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "separate-message"
      },
      "source": [
        "## Network Training\n",
        "\n",
        "Let's now train the network to perform the task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "romantic-recognition",
        "outputId": "9f98d17b-ae0d-4aac-912a-64b7f1176446"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RNNNet(\n",
            "  (rnn): LeakyRNN(\n",
            "    (input2h): Linear(in_features=3, out_features=128, bias=True)\n",
            "    (h2h): Linear(in_features=128, out_features=128, bias=True)\n",
            "  )\n",
            "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
            ")\n",
            "Training network...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pigwi\\miniconda3\\envs\\Cog-AI\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.new_trial to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.new_trial` for environment variables or `env.get_wrapper_attr('new_trial')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "c:\\Users\\pigwi\\miniconda3\\envs\\Cog-AI\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.ob to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.ob` for environment variables or `env.get_wrapper_attr('ob')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "c:\\Users\\pigwi\\miniconda3\\envs\\Cog-AI\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.gt to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.gt` for environment variables or `env.get_wrapper_attr('gt')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 100, Loss 698.6910, Time 5.5s\n",
            "Step 200, Loss 0.1174, Time 11.0s\n",
            "Step 300, Loss 0.0847, Time 16.4s\n",
            "Step 400, Loss 0.0799, Time 21.8s\n",
            "Step 500, Loss 0.0680, Time 27.2s\n",
            "Step 600, Loss 0.0651, Time 32.7s\n",
            "Step 700, Loss 0.0650, Time 38.1s\n",
            "Step 800, Loss 40886351504995414275062377742336.0000, Time 44.1s\n",
            "Step 900, Loss 42169473266029274836514572861440.0000, Time 49.6s\n",
            "Step 1000, Loss 33849589866827737040422927597568.0000, Time 55.0s\n",
            "Step 1100, Loss 37117813600666915246136931385344.0000, Time 60.5s\n",
            "Step 1200, Loss 36931003741124771041341905829888.0000, Time 65.9s\n",
            "Step 1300, Loss 39711515797345886396563190710272.0000, Time 71.3s\n",
            "Step 1400, Loss 50195032413983937690002138333184.0000, Time 76.9s\n",
            "Step 1500, Loss 36690867114788230557697201668096.0000, Time 82.4s\n",
            "Step 1600, Loss 37953071270738503677377880522752.0000, Time 88.0s\n",
            "Step 1700, Loss 41207867921061076690691568959488.0000, Time 93.4s\n",
            "Step 1800, Loss 39018059624403326039440010248192.0000, Time 99.3s\n",
            "Step 1900, Loss 37621478437287310026569227960320.0000, Time 104.7s\n",
            "Step 2000, Loss 36526155609140218050832525950976.0000, Time 110.2s\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the network and print information\n",
        "hidden_size = 128\n",
        "\n",
        "# Create an instance of the Class RNNNet\n",
        "net = RNNNet(input_size=input_size,\n",
        "             hidden_size=hidden_size,\n",
        "             output_size=output_size)\n",
        "print(net)\n",
        "\n",
        "def train_model(net, dataset):\n",
        "    \"\"\"Simple helper function to train the model.\n",
        "\n",
        "    Args:\n",
        "        net: a pytorch nn.Module module\n",
        "        dataset: a dataset object that when called produce a (input, target output) pair\n",
        "\n",
        "    Returns:\n",
        "        net: network object after training\n",
        "    \"\"\"\n",
        "    # Use Adam optimizer\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    running_loss = 0\n",
        "    running_acc = 0\n",
        "    start_time = time.time()\n",
        "    # Loop over training batches\n",
        "    print('Training network...')\n",
        "    for i in range(2000):\n",
        "        # Generate input and target, convert to pytorch tensor\n",
        "        inputs, labels = dataset()\n",
        "        inputs = torch.from_numpy(inputs).type(torch.float)\n",
        "        labels = torch.from_numpy(labels.flatten()).type(torch.long)\n",
        "\n",
        "        # boiler plate pytorch training:\n",
        "        optimizer.zero_grad()   # zero the gradient buffers\n",
        "        output, _ = net(inputs)\n",
        "        # Reshape to (SeqLen x Batch, OutputSize)\n",
        "        output = output.view(-1, output_size)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()    # Does the update\n",
        "\n",
        "        # Compute the running loss every 100 steps\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            running_loss /= 100\n",
        "            print('Step {}, Loss {:0.4f}, Time {:0.1f}s'.format(\n",
        "                i+1, running_loss, time.time() - start_time))\n",
        "            running_loss = 0\n",
        "    return net\n",
        "\n",
        "net = train_model(net, dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "affected-divide"
      },
      "source": [
        "## Testing the network\n",
        "\n",
        "Here we run the network after training, record activity, and compute performance. We will explicitly loop through individual trials, so we can log the information and compute the performance of each trial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yellow-jason",
        "outputId": "bae448bb-eb53-46a5-a602-bb6e47aaa927"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial  0 {'ground_truth': np.int64(1), 'coh': np.float64(25.6), 'correct': np.False_}\n",
            "Trial  1 {'ground_truth': np.int64(1), 'coh': np.float64(25.6), 'correct': np.False_}\n",
            "Trial  2 {'ground_truth': np.int64(1), 'coh': np.float64(51.2), 'correct': np.False_}\n",
            "Trial  3 {'ground_truth': np.int64(1), 'coh': np.float64(6.4), 'correct': np.False_}\n",
            "Trial  4 {'ground_truth': np.int64(1), 'coh': np.float64(51.2), 'correct': np.False_}\n",
            "Average performance 0.0\n"
          ]
        }
      ],
      "source": [
        "# Reset environment\n",
        "env = dataset.env\n",
        "env.reset()\n",
        "\n",
        "# Initialize variables for logging\n",
        "perf = 0\n",
        "activity_dict = {}  # recording activity\n",
        "trial_infos = {}  # recording trial information\n",
        "\n",
        "num_trial = 200\n",
        "for i in range(num_trial):\n",
        "    # Neurogym boiler plate\n",
        "    # Sample a new trial\n",
        "    trial_info = env.new_trial()\n",
        "    # Observation and groud-truth of this trial\n",
        "    ob, gt = env.ob, env.gt\n",
        "    # Convert to numpy, add batch dimension to input\n",
        "    inputs = torch.from_numpy(ob[:, np.newaxis, :]).type(torch.float)\n",
        "\n",
        "    # Run the network for one trial\n",
        "    # inputs (SeqLen, Batch, InputSize)\n",
        "    # action_pred (SeqLen, Batch, OutputSize)\n",
        "    action_pred, rnn_activity = net.forward(inputs)\n",
        "\n",
        "    # Compute performance\n",
        "    # First convert back to numpy\n",
        "    action_pred = action_pred.detach().numpy()[:, 0, :]\n",
        "    # Read out final choice at last time step\n",
        "    choice = np.argmax(action_pred[-1, :])\n",
        "    # Compare to ground truth\n",
        "    correct = choice == gt[-1]\n",
        "\n",
        "    # Record activity, trial information, choice, correctness\n",
        "    rnn_activity = rnn_activity[:, 0, :].detach().numpy()\n",
        "    activity_dict[i] = rnn_activity\n",
        "    trial_infos[i] = trial_info  # trial_info is a dictionary\n",
        "    trial_infos[i].update({'correct': correct})\n",
        "\n",
        "# Print information for sample trials\n",
        "for i in range(5):\n",
        "    print('Trial ', i, trial_infos[i])\n",
        "\n",
        "print('Average performance', np.mean([val['correct'] for val in trial_infos.values()]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azWvNxGVvYW5"
      },
      "source": [
        "## Backpropagation Through Time (BPTT)\n",
        "\n",
        "We will now delve into the world of Recurrent Neural Networks (RNNs), gaining an understanding of their functionality and constructing one from the ground up using only NumPy in Python. Having previously explored backpropagation in feedforward neural networks, we now turn our attention to the complexity introduced by temporal dependencies. Frameworks like PyTorch handle BPTT automatically via autograd. Below, we'll modify our training loop to illustrate how BPTT works under the hood.\n",
        "\n",
        "### Implementing BPTT Step-by-Step\n",
        "We'll implement BPTT manually to illustrate how it works. This involves:\n",
        "\n",
        "Forward Pass: Compute the network's output and store necessary variables.\n",
        "Backward Pass: Compute gradients of the loss with respect to weights by backpropagating errors through time.\n",
        "Weight Updates: Update the weights using the computed gradients.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgUakUuL0jsc"
      },
      "source": [
        "### 1. Forward Pass (Modifying the LeakyRNN Class)\n",
        "\n",
        "We need to store the inputs and hidden states at each time step during the forward pass to use them in the backward pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "81jl1CMq6QPk"
      },
      "outputs": [],
      "source": [
        "class LeakyRNN(nn.Module):\n",
        "    \"\"\"Leaky RNN with BPTT support.\"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, dt=None, **kwargs):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.tau = 100\n",
        "        if dt is None:\n",
        "            alpha = 1\n",
        "        else:\n",
        "            alpha = dt / self.tau\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # Define weights explicitly\n",
        "        self.Wxh = nn.Parameter(torch.randn(hidden_size, input_size) * 0.01)\n",
        "        self.Whh = nn.Parameter(torch.randn(hidden_size, hidden_size) * 0.01)\n",
        "        self.bh = nn.Parameter(torch.zeros(hidden_size))\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return torch.zeros(batch_size, self.hidden_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"Forward pass through time, storing variables for BPTT.\"\"\"\n",
        "        seq_len, batch_size, _ = inputs.size()\n",
        "        hidden = self.init_hidden(batch_size).to(inputs.device)\n",
        "\n",
        "        self.inputs = []   # Store inputs for BPTT\n",
        "        self.hiddens = [hidden]  # Store hidden states for BPTT\n",
        "\n",
        "        outputs = []\n",
        "        for t in range(seq_len):\n",
        "            input_t = inputs[t]\n",
        "            self.inputs.append(input_t)\n",
        "            # Compute pre-activation\n",
        "            pre_activation = self.Wxh @ input_t.T + self.Whh @ hidden.T + self.bh[:, None]\n",
        "            pre_activation = pre_activation.T  # Shape: (batch_size, hidden_size)\n",
        "            # Apply activation function\n",
        "            hidden = (1 - self.alpha) * hidden + self.alpha * torch.tanh(pre_activation)\n",
        "            self.hiddens.append(hidden)\n",
        "            outputs.append(hidden)\n",
        "        outputs = torch.stack(outputs)\n",
        "        return outputs\n",
        "\n",
        "class RNNNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        # Use our modified LeakyRNN\n",
        "        self.rnn = LeakyRNN(input_size, hidden_size, **kwargs)\n",
        "\n",
        "        # Output layer\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        rnn_output = self.rnn(x)\n",
        "        out = self.fc(rnn_output)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igFhTSyt0SUw"
      },
      "source": [
        "### 2. Backward Pass (Manual Gradient Computation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xsOZQCkh54Nu"
      },
      "outputs": [],
      "source": [
        "def bptt(net, outputs, targets):\n",
        "    \"\"\"Manual Backpropagation Through Time.\"\"\"\n",
        "    # Initialize gradients\n",
        "    dWxh = torch.zeros_like(net.rnn.Wxh)\n",
        "    dWhh = torch.zeros_like(net.rnn.Whh)\n",
        "    dbh = torch.zeros_like(net.rnn.bh)\n",
        "    dWhy = torch.zeros_like(net.fc.weight)\n",
        "    dby = torch.zeros_like(net.fc.bias)\n",
        "\n",
        "    # Initialize gradient w.r.t hidden state\n",
        "    dh_next = torch.zeros(outputs.size(1), net.rnn.hidden_size)\n",
        "\n",
        "    seq_len, batch_size, num_classes = outputs.size()\n",
        "\n",
        "    # Compute gradient of loss w.r.t. output logits\n",
        "    outputs_flat = outputs.view(-1, num_classes)\n",
        "    outputs_softmax = torch.softmax(outputs_flat, dim=1)\n",
        "    outputs_softmax = outputs_softmax.view(seq_len, batch_size, num_classes)\n",
        "\n",
        "    # Create one-hot encoding of targets\n",
        "    targets_one_hot = torch.nn.functional.one_hot(targets, num_classes=num_classes).float()\n",
        "\n",
        "    # Compute dy = dL/dy (gradient of loss w.r.t. logits)\n",
        "    dy = outputs_softmax - targets_one_hot  # Shape: (seq_len, batch_size, num_classes)\n",
        "\n",
        "    # Loop backward through time\n",
        "    for t in reversed(range(seq_len)):\n",
        "        # Gradients for output layer\n",
        "        ht = net.rnn.hiddens[t+1]  # Hidden state at time t\n",
        "        dWhy += dy[t].T @ ht\n",
        "        dby += dy[t].sum(0)\n",
        "\n",
        "        # Backprop into hidden layer\n",
        "        dh = dy[t] @ net.fc.weight + dh_next  # Shape: (batch_size, hidden_size)\n",
        "\n",
        "        # Derivative through activation function\n",
        "        dtanh = net.rnn.alpha * (1 - ht ** 2) * dh  # Shape: (batch_size, hidden_size)\n",
        "\n",
        "        # Gradients w.r.t parameters\n",
        "        xt = net.rnn.inputs[t]  # Input at time t\n",
        "        ht_prev = net.rnn.hiddens[t]  # Hidden state at time t-1\n",
        "        dWxh += dtanh.T @ xt\n",
        "        dWhh += dtanh.T @ ht_prev\n",
        "        dbh += dtanh.sum(0)\n",
        "\n",
        "        # Prepare dh_next for next iteration\n",
        "        dh_next = dh * (1 - net.rnn.alpha) + dtanh @ net.rnn.Whh.T\n",
        "\n",
        "    # Clip gradients to prevent exploding gradients\n",
        "    clip_value = 1.0\n",
        "    for grad in [dWxh, dWhh, dbh, dWhy, dby]:\n",
        "        grad.clamp_(-clip_value, clip_value)\n",
        "\n",
        "    # Update weights manually\n",
        "    learning_rate = 0.001\n",
        "    net.rnn.Wxh.data -= learning_rate * dWxh\n",
        "    net.rnn.Whh.data -= learning_rate * dWhh\n",
        "    net.rnn.bh.data -= learning_rate * dbh\n",
        "    net.fc.weight.data -= learning_rate * dWhy\n",
        "    net.fc.bias.data -= learning_rate * dby\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p9E7-wE0Sk9"
      },
      "source": [
        "### 3. Weight Updates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "W3lzuKO17mup"
      },
      "outputs": [],
      "source": [
        "def train_model_bptt(net, dataset):\n",
        "    \"\"\"Train the model using manual BPTT.\"\"\"\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    running_loss = 0\n",
        "    print('Training network with BPTT...')\n",
        "    for i in range(2000):\n",
        "        # Generate input and target, convert to PyTorch tensors\n",
        "        inputs, labels = dataset()\n",
        "        inputs = torch.from_numpy(inputs).type(torch.float)  # Shape: (seq_len, batch_size, input_size)\n",
        "        labels = torch.from_numpy(labels).type(torch.long)   # Shape: (seq_len, batch_size)\n",
        "\n",
        "        # Zero gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = net(inputs)  # outputs shape: (seq_len, batch_size, num_classes)\n",
        "\n",
        "        # Compute loss\n",
        "        outputs_flat = outputs.view(-1, outputs.size(-1))    # Shape: (seq_len * batch_size, num_classes)\n",
        "        labels_flat = labels.view(-1)                        # Shape: (seq_len * batch_size)\n",
        "        loss = criterion(outputs_flat, labels_flat)\n",
        "\n",
        "        # Backward pass using manual BPTT\n",
        "        bptt(net, outputs, labels)\n",
        "\n",
        "        # Logging\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            running_loss /= 100\n",
        "            print('Step {}, Loss {:0.4f}'.format(i+1, running_loss))\n",
        "            running_loss = 0\n",
        "    return net\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p75aoq6L8OKT"
      },
      "source": [
        "### Training the Network with BPTT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8JVRPtf8Phf",
        "outputId": "9307dc25-488c-4832-a08a-4a3685ca26c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training network with BPTT...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pigwi\\miniconda3\\envs\\Cog-AI\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.dt to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.dt` for environment variables or `env.get_wrapper_attr('dt')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 100, Loss 0.5624\n",
            "Step 200, Loss 0.3396\n",
            "Step 300, Loss 0.2714\n",
            "Step 400, Loss 0.2132\n",
            "Step 500, Loss 0.1703\n",
            "Step 600, Loss 0.1340\n",
            "Step 700, Loss 0.0996\n",
            "Step 800, Loss 0.0839\n",
            "Step 900, Loss 0.0742\n",
            "Step 1000, Loss 0.0666\n",
            "Step 1100, Loss 0.0615\n",
            "Step 1200, Loss 0.0579\n",
            "Step 1300, Loss 0.0555\n",
            "Step 1400, Loss 0.0539\n",
            "Step 1500, Loss 0.0522\n",
            "Step 1600, Loss 0.0511\n",
            "Step 1700, Loss 0.0497\n",
            "Step 1800, Loss 0.0481\n",
            "Step 1900, Loss 0.0488\n",
            "Step 2000, Loss 0.0468\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the network\n",
        "hidden_size = 32\n",
        "net = RNNNet(input_size=input_size, hidden_size=hidden_size,\n",
        "             output_size=output_size, dt=env.dt)\n",
        "\n",
        "# Train the network\n",
        "net = train_model_bptt(net, dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaLVcE2S8UwZ"
      },
      "source": [
        "### Testing the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KMfNkC1e32C9"
      },
      "outputs": [],
      "source": [
        "def test_model(net, env, num_trial=200):\n",
        "    # Initialize variables for logging\n",
        "    activity_dict = {}  # recording activity\n",
        "    trial_infos = {}  # recording trial information\n",
        "    for i in range(num_trial):\n",
        "        # Sample a new trial\n",
        "        trial_info = env.new_trial()\n",
        "        # Observation and ground-truth of this trial\n",
        "        ob, gt = env.ob, env.gt\n",
        "        # Convert to tensor, add batch dimension to input\n",
        "        inputs = torch.from_numpy(ob[:, np.newaxis, :]).type(torch.float)\n",
        "        # Run the network for one trial\n",
        "        outputs = net(inputs)\n",
        "        outputs = outputs.detach().numpy()[:, 0, :]\n",
        "        # Compute performance\n",
        "        choice = np.argmax(outputs[-1, :])\n",
        "        correct = choice == gt[-1]\n",
        "        # Record activity, trial information, choice, correctness\n",
        "        activity_dict[i] = outputs\n",
        "        trial_infos[i] = trial_info  # trial_info is a dictionary\n",
        "        trial_infos[i].update({'correct': correct})\n",
        "    return trial_infos, activity_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iah1FZ58W7S",
        "outputId": "942a149c-273d-44c6-b2da-c0a65290fe9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average performance 0.9\n"
          ]
        }
      ],
      "source": [
        "trial_infos, activity_dict = test_model(net, env, num_trial=200)\n",
        "print('Average performance', np.mean([val['correct'] for val in trial_infos.values()]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY62ZtMT-xhx"
      },
      "source": [
        "\n",
        "*Acknowledgments*\n",
        "\n",
        "*Special thanks to Guangyu Robert Yang for their [original work](https://github.com/gyyang/nn-brain/blob/master/RNN_tutorial.ipynb), which served as a foundation for this tutorial.*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Cog-AI",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
